{
  "confidence": 4,
  "confidence_reasoning": "You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
  "strength_and_weaknesses": "Strength:\n- The proposed modifications are straightforward and easy to follow. They are easily reproducible as most of the components have been released by previous works.\n- Various figures (2 & 3) are helpful in comprehending the proposed changes.\n- I appreciate the ablation study of those 3 components with detailed performance analysis.\n\nWeaknesses\n- As discussed in related work by the authors themselves, all 3 components have been proven useful. The multi-crop data augmentation and expendable projector head are now widely used in various self-supervised learning approaches. Directly applying and combining 3 well known components in my opinion does not necessarily guarantee meeting the novelty bar at ICLR.\n- For example, since AlexNet, VGG, and ResNet, various different image cropping methods have been proposed. With the recent semi-supervised learning advances, we now know that more aggressive image cropping can generally make the training task harder, making the network learn harder and generalize better. The authors found that multi-crop data augmentation from [Caron et al 2020] also works well on ResNet under supervised learning setting should not be a huge surprise.\n- Also, expendable projector head essentially forces the downstream tasks to use feature representations from the earlier layer (not the last layer) has also been largely explored such as [A1, A2]. One can essentially use any combination of any previous layers for the downstream task training. \n- The major challenge in transferring features learned from supervised learning is that it generally does not perform well on class-imbalanced downstream tasks. This is due to during supervised learning, the features are learned to tailor the class distribution from the pre-training set. It would be great that the authors can shed more light on this for any future improvement of the manuscript.\n\n[A1] Lin et al. Feature Pyramid Networks for Object Detection. CVPR\u201917\n[A2] Lee et al. Deeply-Supervised Nets. AISTATS\u201915\n",
  "summary_of_the_paper": "The authors revisit the paradigm of supervised learning with recent successful breakthroughs in self-supervised learning, including multi-crop data augmentation [Caron et al., 2020], expendable projector head [Chen et al., 2020a], and a variant of nearest class means classifier [Mensink et al., 2012]. They found that those components, while working well with self-supervised settings, also work well with conventional supervised settings. Combined with those 3 components, the authors show improvement over other supervised, self-supervised, and semi-supervised approaches for ResNet-50."
}